import sys
import os
import pandas as pd
import datetime
import glob
from typing import List, Tuple
from tqdm import tqdm

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from common.data import StockCodeMaster
from common.rss import TickType
from common import common, columns

S_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
S_INPUT_DIR = os.path.join(S_FILE_DIR, 'input')
S_OUTPUT_DIR = os.path.join(S_FILE_DIR, 'output')

class BreakNewHighAnalyzer:
    """æ–°é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯æŠ•è³‡æ³•ã®åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.stock_code_master = StockCodeMaster()
        self.stock_code_master.load()
        self.market_data = None
        self._load_market_data()
    
    def _load_market_data(self):
        """
        å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        """
        market_data_path = os.path.join(S_INPUT_DIR, 'market_data', 'rss_market_data.csv')
        if os.path.exists(market_data_path):
            try:
                with tqdm(desc="ğŸ“Š å¸‚å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿", unit="ä»¶", leave=False) as pbar:
                    self.market_data = pd.read_csv(market_data_path, encoding='utf-8-sig')
                    pbar.total = len(self.market_data)
                    pbar.update(len(self.market_data))
                    
                    # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—å‹ã«çµ±ä¸€ï¼ˆå°æ•°ç‚¹ã‚’å‰Šé™¤ï¼‰
                    if 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰' in self.market_data.columns:
                        self.market_data['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] = self.market_data['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'].astype(str).str.replace('.0', '', regex=False)
                    
                    tqdm.write(f"âœ… å¸‚å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.market_data)}ä»¶")
            except Exception as e:
                tqdm.write(f"âš ï¸ å¸‚å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                self.market_data = None
        else:
            tqdm.write(f"âš ï¸ å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {market_data_path}")
            self.market_data = None
    
    def get_stock_info(self, stock_code: str) -> dict:
        """
        éŠ˜æŸ„æƒ…å ±ã‚’å–å¾—ï¼ˆéŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ã¨å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        
        Args:
            stock_code: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            éŠ˜æŸ„æƒ…å ±ã®è¾æ›¸
        """
        stock_code_str = str(stock_code).strip()
        
        # éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ã‹ã‚‰éŠ˜æŸ„åã‚’å–å¾—
        stock_info = self.stock_code_master.get_by_code(stock_code_str)
        stock_name = stock_info['name'].iloc[0] if not stock_info.empty else "ä¸æ˜"
        
        # çµæœã®åˆæœŸåŒ–
        result = {'éŠ˜æŸ„å': stock_name}
        
        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼ˆpandasã®mergeã‚’ä½¿ç”¨ï¼‰
        if self.market_data is not None:
            # ä¸€æ™‚çš„ãªDataFrameã‚’ä½œæˆã—ã¦merge
            temp_df = pd.DataFrame({'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰': [stock_code_str]})
            merged_data = temp_df.merge(
                self.market_data, 
                on='éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰', 
                how='left'
            )
            
            if not merged_data.empty and not merged_data.iloc[0].isna().all():
                # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã™ã‚‹é‡è¦ãªæŒ‡æ¨™ã‚’æ‹¡å……
                market_columns = [
                    # åŸºæœ¬æƒ…å ±
                    'éŠ˜æŸ„åç§°', 'å¸‚å ´åç§°', 'å¸‚å ´éƒ¨åç§°', 'å¸‚å ´éƒ¨ç•¥ç§°',
                    # ä¾¡æ ¼æƒ…å ±
                    'ç¾åœ¨å€¤', 'å‰æ—¥æ¯”', 'å‰æ—¥æ¯”ç‡', 'å‰æ—¥çµ‚å€¤', 'å§‹å€¤', 'é«˜å€¤', 'å®‰å€¤',
                    # å–å¼•æƒ…å ±
                    'å‡ºæ¥é«˜', 'å£²è²·ä»£é‡‘', 'å‡ºæ¥é«˜åŠ é‡å¹³å‡', 'æ™‚ä¾¡ç·é¡',
                    # è²¡å‹™æŒ‡æ¨™
                    'PER', 'PBR', 'é…å½“',
                    # ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸
                    'å¹´åˆæ¥é«˜å€¤', 'å¹´åˆæ¥å®‰å€¤', 'å¹´åˆæ¥é«˜å€¤æ—¥ä»˜', 'å¹´åˆæ¥å®‰å€¤æ—¥ä»˜',
                    'ä¸Šå ´æ¥é«˜å€¤', 'ä¸Šå ´æ¥å®‰å€¤', 'ä¸Šå ´æ¥é«˜å€¤æ—¥ä»˜', 'ä¸Šå ´æ¥å®‰å€¤æ—¥ä»˜',
                    # ä¿¡ç”¨å–å¼•æƒ…å ±
                    'ä¿¡ç”¨å€ç‡', 'é€†æ—¥æ­©', 'ä¿¡ç”¨å£²æ®‹', 'ä¿¡ç”¨è²·æ®‹', 'ä¿¡ç”¨å£²æ®‹å‰é€±æ¯”', 'ä¿¡ç”¨è²·æ®‹å‰é€±æ¯”',
                    'è²¸å€Ÿå€ç‡', 'å›è»¢æ—¥æ•°',
                    # ãã®ä»–æŒ‡æ¨™
                    'å˜ä½æ ªæ•°', 'é…å½“è½æ—¥', 'æ±ºç®—ç™ºè¡¨æ—¥', 'è²¸æ ªé‡‘åˆ©',
                    # æ°—é…æƒ…å ±
                    'æœ€è‰¯å£²æ°—é…å€¤', 'æœ€è‰¯è²·æ°—é…å€¤'
                ]
                
                for col in market_columns:
                    if col in merged_data.columns:
                        value = merged_data[col].iloc[0]
                        # NaNã€ç©ºæ–‡å­—åˆ—ã€0.0ã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                        if pd.notna(value) and value != '' and value != 0.0:
                            result[col] = value
                
                # éŠ˜æŸ„åç§°ãŒå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã«ã‚ã‚‹å ´åˆã¯å„ªå…ˆ
                if 'éŠ˜æŸ„åç§°' in result:
                    result['éŠ˜æŸ„å'] = result['éŠ˜æŸ„åç§°']
        
        return result
    
    def load_stock_data_from_folder(self, folder_path: str) -> pd.DataFrame:
        """
        æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å…¨éŠ˜æŸ„ã®CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€çµ±åˆã—ãŸDataFrameã‚’ä½œæˆ
        
        Args:
            folder_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹
            
        Returns:
            çµ±åˆã•ã‚ŒãŸDataFrame
        """
        all_data = []
        csv_files = glob.glob(os.path.join(folder_path, "*.csv"))
        
        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–
        csv_files = [f for f in csv_files if 'rss_market_data.csv' not in f]
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§èª­ã¿è¾¼ã¿é€²è¡ŒçŠ¶æ³ã‚’è¡¨ç¤º
        with tqdm(total=len(csv_files), desc="ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿", unit="file") as pbar:
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file, encoding='utf-8-sig')
                    if not df.empty:
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆä¾‹: stock_chart_W_130A_20240719_20250711.csvï¼‰
                        filename = os.path.basename(csv_file)
                        if 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰' not in df.columns:
                            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
                            parts = filename.split('_')
                            if len(parts) >= 3:
                                stock_code = parts[2]
                                df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] = stock_code
                        
                        # å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æœ‰åŠ¹ã‹ï¼‰
                        required_columns = ['æ—¥ä»˜', 'é«˜å€¤', 'çµ‚å€¤', 'å‡ºæ¥é«˜']
                        if all(col in df.columns for col in required_columns):
                            all_data.append(df)
                        else:
                            tqdm.write(f"âš ï¸ å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—: {filename}")
                            
                    pbar.set_postfix({"ãƒ•ã‚¡ã‚¤ãƒ«": os.path.basename(csv_file)})
                except Exception as e:
                    tqdm.write(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {csv_file}, ã‚¨ãƒ©ãƒ¼: {e}")
                pbar.update(1)
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—å‹ã«çµ±ä¸€
            combined_df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] = combined_df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'].astype(str)
            tqdm.write(f"âœ… çµ±åˆå®Œäº†: {len(combined_df):,}ä»¶ã®ãƒ‡ãƒ¼ã‚¿, {combined_df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'].nunique()}éŠ˜æŸ„")
            return combined_df
        else:
            tqdm.write("âš ï¸ èª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return pd.DataFrame()
    
    def find_new_highs(self, df: pd.DataFrame, period_weeks: int = 52) -> pd.DataFrame:
        """
        æ–°é«˜å€¤ã‚’ä»˜ã‘ãŸéŠ˜æŸ„ã‚’é¸å‡º
        
        Args:
            df: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            period_weeks: é«˜å€¤æ›´æ–°æœŸé–“ï¼ˆé€±æ•°ï¼‰
            
        Returns:
            æ–°é«˜å€¤éŠ˜æŸ„ã®DataFrame
        """
        new_high_stocks = []
        stock_codes = df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'].unique()
        
        # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã”ã¨ã«åˆ†æ
        with tqdm(total=len(stock_codes), desc="ğŸ” æ–°é«˜å€¤éŠ˜æŸ„æ¤œç´¢", unit="éŠ˜æŸ„") as pbar:
            for stock_code in stock_codes:
                stock_df = df[df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] == stock_code].copy()
                
                if len(stock_df) == 0:
                    pbar.update(1)
                    continue
                
                # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
                try:
                    stock_df['æ—¥ä»˜'] = pd.to_datetime(stock_df['æ—¥ä»˜'])
                    stock_df = stock_df.sort_values('æ—¥ä»˜').reset_index(drop=True)
                except Exception as e:
                    tqdm.write(f"âš ï¸ éŠ˜æŸ„ {stock_code} ã®æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                    pbar.update(1)
                    continue
                
                # æœ€æ–°ã®é«˜å€¤ã‚’å–å¾—
                latest_high = stock_df['é«˜å€¤'].iloc[-1]
                latest_date = stock_df['æ—¥ä»˜'].iloc[-1]
                
                # éå»ã®æœ€é«˜å€¤ã‚’è¨ˆç®—ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’é™¤ãï¼‰
                if len(stock_df) > 1:
                    historical_data = stock_df.iloc[:-1]
                    historical_max = historical_data['é«˜å€¤'].max()
                    
                    # æ–°é«˜å€¤åˆ¤å®š
                    if latest_high > historical_max:
                        # éŠ˜æŸ„æƒ…å ±ã‚’å–å¾— - éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã®å‹ã‚’ç¢ºå®Ÿã«æ–‡å­—åˆ—ã«ã™ã‚‹
                        stock_code_str = str(stock_code).strip()
                        stock_info = self.get_stock_info(stock_code_str)
                        
                        new_high_stocks.append({
                            'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰': stock_code_str,
                            'éŠ˜æŸ„å': stock_info['éŠ˜æŸ„å'],
                            'æ–°é«˜å€¤': latest_high,
                            'æ–°é«˜å€¤æ—¥ä»˜': latest_date,
                            'éå»æœ€é«˜å€¤': historical_max,
                            'é«˜å€¤æ›´æ–°ç‡': ((latest_high - historical_max) / historical_max * 100),
                            'åˆ†ææœŸé–“_é€±': period_weeks,
                            'æœ€æ–°çµ‚å€¤': stock_df['çµ‚å€¤'].iloc[-1],
                            'æœ€æ–°å‡ºæ¥é«˜': stock_df['å‡ºæ¥é«˜'].iloc[-1],
                            # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã‚’è¿½åŠ 
                            'å¸‚å ´åç§°': stock_info.get('å¸‚å ´åç§°'),
                            'å¸‚å ´éƒ¨åç§°': stock_info.get('å¸‚å ´éƒ¨åç§°'),
                            'ç¾åœ¨å€¤': stock_info.get('ç¾åœ¨å€¤'),
                            'å‰æ—¥æ¯”': stock_info.get('å‰æ—¥æ¯”'),
                            'å‰æ—¥æ¯”ç‡': stock_info.get('å‰æ—¥æ¯”ç‡'),
                            'PER': stock_info.get('PER'),
                            'PBR': stock_info.get('PBR'),
                            'é…å½“': stock_info.get('é…å½“'),
                            'æ™‚ä¾¡ç·é¡': stock_info.get('æ™‚ä¾¡ç·é¡'),
                            'å£²è²·ä»£é‡‘': stock_info.get('å£²è²·ä»£é‡‘'),
                            'å¹´åˆæ¥é«˜å€¤': stock_info.get('å¹´åˆæ¥é«˜å€¤'),
                            'å¹´åˆæ¥å®‰å€¤': stock_info.get('å¹´åˆæ¥å®‰å€¤'),
                            'å¹´åˆæ¥é«˜å€¤æ—¥ä»˜': stock_info.get('å¹´åˆæ¥é«˜å€¤æ—¥ä»˜'),
                            'å¹´åˆæ¥å®‰å€¤æ—¥ä»˜': stock_info.get('å¹´åˆæ¥å®‰å€¤æ—¥ä»˜'),
                            'ä¸Šå ´æ¥é«˜å€¤': stock_info.get('ä¸Šå ´æ¥é«˜å€¤'),
                            'ä¸Šå ´æ¥å®‰å€¤': stock_info.get('ä¸Šå ´æ¥å®‰å€¤'),
                            'ä¿¡ç”¨å€ç‡': stock_info.get('ä¿¡ç”¨å€ç‡'),
                            'ä¿¡ç”¨å£²æ®‹': stock_info.get('ä¿¡ç”¨å£²æ®‹'),
                            'ä¿¡ç”¨è²·æ®‹': stock_info.get('ä¿¡ç”¨è²·æ®‹'),
                            'è²¸å€Ÿå€ç‡': stock_info.get('è²¸å€Ÿå€ç‡'),
                            'å›è»¢æ—¥æ•°': stock_info.get('å›è»¢æ—¥æ•°'),
                            'å˜ä½æ ªæ•°': stock_info.get('å˜ä½æ ªæ•°'),
                            'æ±ºç®—ç™ºè¡¨æ—¥': stock_info.get('æ±ºç®—ç™ºè¡¨æ—¥'),
                            'è²¸æ ªé‡‘åˆ©': stock_info.get('è²¸æ ªé‡‘åˆ©')
                        })
                
                pbar.update(1)
        
        result_df = pd.DataFrame(new_high_stocks)
        
        if not result_df.empty:
            # é«˜å€¤æ›´æ–°ç‡ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
            result_df = result_df.sort_values('é«˜å€¤æ›´æ–°ç‡', ascending=False).reset_index(drop=True)
            tqdm.write(f"ğŸ‰ æ–°é«˜å€¤éŠ˜æŸ„æ•°: {len(result_df)}éŠ˜æŸ„")
        else:
            tqdm.write("ğŸ“‰ æ–°é«˜å€¤ã‚’ä»˜ã‘ãŸéŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        return result_df
    
    def find_near_new_highs(self, df: pd.DataFrame, threshold_percent: float = 5.0) -> pd.DataFrame:
        """
        æ–°é«˜å€¤ã‚’æ›´æ–°ã—ãã†ãªæ ªã‚’é¸å‡ºï¼ˆéå»é«˜å€¤ã®-X%ä»¥å†…ï¼‰
        
        Args:
            df: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            threshold_percent: éå»é«˜å€¤ã‹ã‚‰ã®ä¹–é›¢é–¾å€¤ï¼ˆ%ï¼‰
            
        Returns:
            æ–°é«˜å€¤æ›´æ–°å€™è£œéŠ˜æŸ„ã®DataFrame
        """
        near_high_stocks = []
        stock_codes = df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'].unique()
        
        # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã”ã¨ã«åˆ†æ
        with tqdm(total=len(stock_codes), desc="ğŸ” å€™è£œéŠ˜æŸ„æ¤œç´¢", unit="éŠ˜æŸ„") as pbar:
            for stock_code in stock_codes:
                stock_df = df[df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] == stock_code].copy()
                
                if len(stock_df) == 0:
                    pbar.update(1)
                    continue
                
                # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
                try:
                    stock_df['æ—¥ä»˜'] = pd.to_datetime(stock_df['æ—¥ä»˜'])
                    stock_df = stock_df.sort_values('æ—¥ä»˜').reset_index(drop=True)
                except Exception as e:
                    tqdm.write(f"âš ï¸ éŠ˜æŸ„ {stock_code} ã®æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                    pbar.update(1)
                    continue
                
                # æœ€æ–°ã®çµ‚å€¤ã‚’å–å¾—
                latest_close = stock_df['çµ‚å€¤'].iloc[-1]
                latest_date = stock_df['æ—¥ä»˜'].iloc[-1]
                
                # éå»ã®æœ€é«˜å€¤ã‚’è¨ˆç®—
                historical_max = stock_df['é«˜å€¤'].max()
                
                # æ–°é«˜å€¤æ›´æ–°å€™è£œã®é–¾å€¤ã‚’è¨ˆç®—
                threshold_price = historical_max * (1 - threshold_percent / 100)
                
                # é«˜å€¤ã¾ã§ã®ä¹–é›¢ç‡ã‚’è¨ˆç®—
                divergence_rate = ((historical_max - latest_close) / historical_max * 100)
                
                # æ–°é«˜å€¤æ›´æ–°å€™è£œåˆ¤å®š
                if latest_close >= threshold_price and latest_close < historical_max:
                    # éŠ˜æŸ„æƒ…å ±ã‚’å–å¾— - éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã®å‹ã‚’ç¢ºå®Ÿã«æ–‡å­—åˆ—ã«ã™ã‚‹
                    stock_code_str = str(stock_code).strip()
                    stock_info = self.get_stock_info(stock_code_str)
                    
                    near_high_stocks.append({
                        'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰': stock_code_str,
                        'éŠ˜æŸ„å': stock_info['éŠ˜æŸ„å'],
                        'æœ€æ–°çµ‚å€¤': latest_close,
                        'æœ€æ–°æ—¥ä»˜': latest_date,
                        'éå»æœ€é«˜å€¤': historical_max,
                        'é«˜å€¤ã¾ã§ã®ä¹–é›¢ç‡': divergence_rate,
                        'é–¾å€¤ä¾¡æ ¼': threshold_price,
                        'é–¾å€¤_ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ': threshold_percent,
                        'æœ€æ–°å‡ºæ¥é«˜': stock_df['å‡ºæ¥é«˜'].iloc[-1],
                        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã‚’è¿½åŠ 
                        'å¸‚å ´åç§°': stock_info.get('å¸‚å ´åç§°'),
                        'å¸‚å ´éƒ¨åç§°': stock_info.get('å¸‚å ´éƒ¨åç§°'),
                        'ç¾åœ¨å€¤': stock_info.get('ç¾åœ¨å€¤'),
                        'å‰æ—¥æ¯”': stock_info.get('å‰æ—¥æ¯”'),
                        'å‰æ—¥æ¯”ç‡': stock_info.get('å‰æ—¥æ¯”ç‡'),
                        'PER': stock_info.get('PER'),
                        'PBR': stock_info.get('PBR'),
                        'é…å½“': stock_info.get('é…å½“'),
                        'æ™‚ä¾¡ç·é¡': stock_info.get('æ™‚ä¾¡ç·é¡'),
                        'å£²è²·ä»£é‡‘': stock_info.get('å£²è²·ä»£é‡‘'),
                        'å¹´åˆæ¥é«˜å€¤': stock_info.get('å¹´åˆæ¥é«˜å€¤'),
                        'å¹´åˆæ¥å®‰å€¤': stock_info.get('å¹´åˆæ¥å®‰å€¤'),
                        'å¹´åˆæ¥é«˜å€¤æ—¥ä»˜': stock_info.get('å¹´åˆæ¥é«˜å€¤æ—¥ä»˜'),
                        'å¹´åˆæ¥å®‰å€¤æ—¥ä»˜': stock_info.get('å¹´åˆæ¥å®‰å€¤æ—¥ä»˜'),
                        'ä¸Šå ´æ¥é«˜å€¤': stock_info.get('ä¸Šå ´æ¥é«˜å€¤'),
                        'ä¸Šå ´æ¥å®‰å€¤': stock_info.get('ä¸Šå ´æ¥å®‰å€¤'),
                        'ä¿¡ç”¨å€ç‡': stock_info.get('ä¿¡ç”¨å€ç‡'),
                        'ä¿¡ç”¨å£²æ®‹': stock_info.get('ä¿¡ç”¨å£²æ®‹'),
                        'ä¿¡ç”¨è²·æ®‹': stock_info.get('ä¿¡ç”¨è²·æ®‹'),
                        'è²¸å€Ÿå€ç‡': stock_info.get('è²¸å€Ÿå€ç‡'),
                        'å›è»¢æ—¥æ•°': stock_info.get('å›è»¢æ—¥æ•°'),
                        'å˜ä½æ ªæ•°': stock_info.get('å˜ä½æ ªæ•°'),
                        'æ±ºç®—ç™ºè¡¨æ—¥': stock_info.get('æ±ºç®—ç™ºè¡¨æ—¥'),
                        'è²¸æ ªé‡‘åˆ©': stock_info.get('è²¸æ ªé‡‘åˆ©')
                    })
                
                pbar.update(1)
        
        result_df = pd.DataFrame(near_high_stocks)
        
        if not result_df.empty:
            # é«˜å€¤ã¾ã§ã®ä¹–é›¢ç‡ã§ã‚½ãƒ¼ãƒˆï¼ˆæ˜‡é †ï¼‰
            result_df = result_df.sort_values('é«˜å€¤ã¾ã§ã®ä¹–é›¢ç‡', ascending=True).reset_index(drop=True)
            tqdm.write(f"ğŸ¯ æ–°é«˜å€¤å€™è£œéŠ˜æŸ„æ•°: {len(result_df)}éŠ˜æŸ„")
        else:
            tqdm.write("ğŸ“‰ æ–°é«˜å€¤æ›´æ–°å€™è£œéŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        return result_df
    
    def save_results(self, df: pd.DataFrame, filename: str, analysis_type: str):
        """
        åˆ†æçµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            df: ä¿å­˜ã™ã‚‹DataFrame
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            analysis_type: åˆ†æç¨®åˆ¥
        """
        # å®Ÿè¡Œæ—¥ä»˜ã‚’å–å¾—
        exec_date = datetime.datetime.now().strftime('%Y%m%d')
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        output_folder = os.path.join(S_OUTPUT_DIR, f"{exec_date}_{analysis_type}")
        os.makedirs(output_folder, exist_ok=True)
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        output_path = os.path.join(output_folder, filename)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        tqdm.write(f"ğŸ’¾ çµæœä¿å­˜: {filename} ({len(df)}ä»¶)")
        
        return output_path

def analyze_folder_data(folder_name: str):
    """
    æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹
    
    Args:
        folder_name: åˆ†æå¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€åï¼ˆä¾‹: W_52_20250713ï¼‰
    """
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§åˆ†æå…¨ä½“ã®é€²è¡ŒçŠ¶æ³ã‚’è¡¨ç¤º
    with tqdm(total=4, desc=f"ğŸ“Š {folder_name} åˆ†æ", unit="step") as main_pbar:
        analyzer = BreakNewHighAnalyzer()
        main_pbar.set_postfix({"ã‚¹ãƒ†ãƒƒãƒ—": "åˆæœŸåŒ–"})
        main_pbar.update(1)
        
        # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        folder_path = os.path.join(S_INPUT_DIR, folder_name)
        
        if not os.path.exists(folder_path):
            tqdm.write(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {folder_path}")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        main_pbar.set_postfix({"ã‚¹ãƒ†ãƒƒãƒ—": "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"})
        df = analyzer.load_stock_data_from_folder(folder_path)
        main_pbar.update(1)
        
        if df.empty:
            tqdm.write("âš ï¸ åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰æœŸé–“ã‚’æŠ½å‡ºï¼ˆä¾‹: W_52_20250713 -> 52é€±ï¼‰
        parts = folder_name.split('_')
        if len(parts) >= 2:
            try:
                period_weeks = int(parts[1])
            except ValueError:
                period_weeks = 52  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        else:
            period_weeks = 52
        
        analysis_type = f"{period_weeks}week"
        
        # 1. æ–°é«˜å€¤éŠ˜æŸ„ã®é¸å‡º
        main_pbar.set_postfix({"ã‚¹ãƒ†ãƒƒãƒ—": "æ–°é«˜å€¤éŠ˜æŸ„é¸å‡º"})
        new_highs_df = analyzer.find_new_highs(df, period_weeks)
        if not new_highs_df.empty:
            analyzer.save_results(
                new_highs_df, 
                f"new_highs_{period_weeks}week.csv", 
                analysis_type
            )
        main_pbar.update(1)
        
        # 2. æ–°é«˜å€¤æ›´æ–°å€™è£œéŠ˜æŸ„ã®é¸å‡º
        main_pbar.set_postfix({"ã‚¹ãƒ†ãƒƒãƒ—": "å€™è£œéŠ˜æŸ„é¸å‡º"})
        near_highs_df = analyzer.find_near_new_highs(df, threshold_percent=5.0)
        if not near_highs_df.empty:
            analyzer.save_results(
                near_highs_df, 
                f"near_new_highs_{period_weeks}week.csv", 
                analysis_type
            )
        main_pbar.update(1)
        
        # çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        tqdm.write(f"\n=== ğŸ“Š {folder_name} åˆ†æçµæœã‚µãƒãƒªãƒ¼ ===")
        if not new_highs_df.empty:
            tqdm.write(f"ğŸ† æ–°é«˜å€¤éŠ˜æŸ„æ•°: {len(new_highs_df)}éŠ˜æŸ„")
            tqdm.write("=== æ–°é«˜å€¤éŠ˜æŸ„ãƒˆãƒƒãƒ—10 ===")
            top_new_highs = new_highs_df[['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„å', 'æ–°é«˜å€¤', 'é«˜å€¤æ›´æ–°ç‡']].head(10)
            for _, row in top_new_highs.iterrows():
                tqdm.write(f"  {row['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰']}: {row['éŠ˜æŸ„å']} - æ–°é«˜å€¤:{row['æ–°é«˜å€¤']:.0f} (+{row['é«˜å€¤æ›´æ–°ç‡']:.2f}%)")
        
        if not near_highs_df.empty:
            tqdm.write(f"ğŸ¯ æ–°é«˜å€¤å€™è£œéŠ˜æŸ„æ•°: {len(near_highs_df)}éŠ˜æŸ„")
            tqdm.write("=== æ–°é«˜å€¤æ›´æ–°å€™è£œéŠ˜æŸ„ãƒˆãƒƒãƒ—10 ===")
            top_near_highs = near_highs_df[['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„å', 'æœ€æ–°çµ‚å€¤', 'é«˜å€¤ã¾ã§ã®ä¹–é›¢ç‡']].head(10)
            for _, row in top_near_highs.iterrows():
                tqdm.write(f"  {row['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰']}: {row['éŠ˜æŸ„å']} - çµ‚å€¤:{row['æœ€æ–°çµ‚å€¤']:.0f} (ä¹–é›¢ç‡:{row['é«˜å€¤ã¾ã§ã®ä¹–é›¢ç‡']:.2f}%)")
        
        tqdm.write(f"âœ… åˆ†æå®Œäº†: {folder_name}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # inputãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
    if not os.path.exists(S_INPUT_DIR):
        tqdm.write(f"âŒ inputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {S_INPUT_DIR}")
        return

    # 104é€±ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ãŸã‚ã®ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¨­å®š
    # ä¾‹: W_52_20250713ï¼ˆ52é€±ã®ãƒ‡ãƒ¼ã‚¿ã€2025å¹´7æœˆ13æ—¥å®Ÿè¡Œï¼‰
    tick_type = TickType.WEEK
    number = 104  # 104é€±ã®ãƒ‡ãƒ¼ã‚¿
    date = "20250918"
    target_folder_name = f"{tick_type.value}_{number}_{date}"
    tqdm.write(f"ğŸ” åˆ†æå¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€å: {target_folder_name}")

    # inputãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ï¼ˆmarket_dataã‚’é™¤å¤–ï¼‰
    folders = [f for f in os.listdir(S_INPUT_DIR) 
              if os.path.isdir(os.path.join(S_INPUT_DIR, f)) and f != 'market_data']

    # ãƒ•ã‚©ãƒ«ãƒ€åãŒ104é€±ã®ãƒ‡ãƒ¼ã‚¿ã«ä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    folders = [f for f in folders if f.startswith(target_folder_name)]
    
    if not folders:
        tqdm.write("âš ï¸ åˆ†æå¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ¡ã‚¤ãƒ³é€²è¡ŒçŠ¶æ³ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    with tqdm(total=len(folders), desc="ï¿½ æ–°é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯æŠ•è³‡æ³• åˆ†æ", unit="folder") as main_progress:
        main_progress.set_postfix({"ãƒ•ã‚©ãƒ«ãƒ€æ•°": len(folders)})
        
        # å„ãƒ•ã‚©ãƒ«ãƒ€ã‚’åˆ†æ
        for folder_name in folders:
            try:
                main_progress.set_postfix({"ç¾åœ¨": folder_name})
                analyze_folder_data(folder_name)
                main_progress.update(1)
            except Exception as e:
                tqdm.write(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ {folder_name} ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                main_progress.update(1)
    
    tqdm.write("\n=== ğŸ‰ åˆ†æçµ‚äº† ===")

if __name__ == "__main__":
    main()